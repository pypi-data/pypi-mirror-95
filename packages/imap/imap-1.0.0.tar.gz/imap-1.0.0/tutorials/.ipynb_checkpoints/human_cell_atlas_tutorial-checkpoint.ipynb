{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Cell Atlas Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iMAP workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will show the entire iMAP pipeline using the 'Human cell atlas' dataset. This is a large dataset with 321,463 bone marrow cells in batch 1 and 300,003 cord blood-derived cells in batch 2. And we will use this dataset to measure iMAP's ability to handle big data and measure the time consumed by each part of the processure.\n",
    "\n",
    "The total workfow includes: \n",
    "<ol>\n",
    "    <li>Loading and preprocessing data;</li>\n",
    "    <li>Running the main iMAP two-stage batch effect removal procedure;</li>\n",
    "    <li>(Optional) Visulizations; </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/housy17/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#### IMPORT LIBRARY ####\n",
    "import datetime\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import imap.imap_bd2 as imap\n",
    "import imap.utils_bd2 as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Human cell atlas' dataset is already stored at <a href=''><font color='blue'>'../other_data/ica_cord_blood_h5.h5'</font></a> and <a href=''><font color='blue'>'../other_data/ica_bone_marrow_h5.h5'</font></a>. We use the scanpy API `read_10x_h5` to read the file and store as an 'AnnData' object. Here we record the time it takes to import the data, which on our computer is usually around 18s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "adata1 = sc.read_10x_h5('../other_data/ica_cord_blood_h5.h5')\n",
    "adata2 = sc.read_10x_h5('../other_data/ica_bone_marrow_h5.h5')\n",
    "endtime = datetime.datetime.now()\n",
    "print((endtime-starttime).seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing:** Here we record the time it takes to preprocess the data, which on our computer is usually around 110s. And we acquire 656258 cells with 1615 highly variable genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data in Different Batches...\n",
      "Establishing Adata for Next Step...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcess Done.\n",
      "117\n",
      "AnnData object with n_obs × n_vars = 656258 × 1615\n",
      "    obs: 'batch', 'n_genes', 'n_counts'\n",
      "    var: 'gene_ids', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
      "    uns: 'log1p'\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "genes = sorted(list(set(adata1.var_names)))\n",
    "index_ = list(adata1.var_names)\n",
    "adata1 = adata1[:, [index_.index(gene) for gene in genes]]\n",
    "genes = sorted(list(set(adata2.var_names)))\n",
    "index_ = list(adata2.var_names)\n",
    "adata2 = adata2[:, [index_.index(gene) for gene in genes]]\n",
    "adata = adata1.concatenate(adata2)\n",
    "adata = imap.data_preprocess(adata, 'batch', n_batch=0)  #Preprocess the data.\n",
    "adata.obs['batch'] = np.array([str(item) for item in adata.obs['batch']])\n",
    "adata.X = adata.X.toarray()\n",
    "endtime = datetime.datetime.now()\n",
    "print((endtime-starttime).seconds)\n",
    "print(adata)  #Output the basic information of the preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Batch effect removal by iMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See <font color='red'>Cell Line Tutorial</font> for details on the usage of `iMAP_fast` and `integrate_data`.\n",
    "\n",
    "To verify that the iMAP calculation time is not sensitive to the number of cells, we set the same parameters that we used to process the 'Tabula Muris' dataset. (See main text (Fig. 3e) for the time cost of iMAP versus the number of cells by downsampling from 500 to 100,000 cells of Tabula Muris.)\n",
    "\n",
    "Here we record the time that two iMAP's stages cost, which on our computer is usually around 198s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Calibrating Celltype...\n",
      "[Epoch 1/150] [Reconstruction loss: 0.103402] [Cotent loss: 0.003576]\n",
      "[Epoch 2/150] [Reconstruction loss: 0.097171] [Cotent loss: 0.001406]\n",
      "[Epoch 3/150] [Reconstruction loss: 0.101285] [Cotent loss: 0.000739]\n",
      "[Epoch 4/150] [Reconstruction loss: 0.098104] [Cotent loss: 0.000636]\n",
      "[Epoch 5/150] [Reconstruction loss: 0.100382] [Cotent loss: 0.000403]\n",
      "[Epoch 6/150] [Reconstruction loss: 0.092763] [Cotent loss: 0.000336]\n",
      "[Epoch 7/150] [Reconstruction loss: 0.098847] [Cotent loss: 0.000299]\n",
      "[Epoch 8/150] [Reconstruction loss: 0.099740] [Cotent loss: 0.000314]\n",
      "[Epoch 9/150] [Reconstruction loss: 0.102754] [Cotent loss: 0.000419]\n",
      "[Epoch 10/150] [Reconstruction loss: 0.093942] [Cotent loss: 0.000760]\n",
      "[Epoch 11/150] [Reconstruction loss: 0.092785] [Cotent loss: 0.000488]\n",
      "[Epoch 12/150] [Reconstruction loss: 0.089725] [Cotent loss: 0.000448]\n",
      "[Epoch 13/150] [Reconstruction loss: 0.088000] [Cotent loss: 0.000438]\n",
      "[Epoch 14/150] [Reconstruction loss: 0.085991] [Cotent loss: 0.000386]\n",
      "[Epoch 15/150] [Reconstruction loss: 0.083329] [Cotent loss: 0.000259]\n",
      "[Epoch 16/150] [Reconstruction loss: 0.081826] [Cotent loss: 0.000296]\n",
      "[Epoch 17/150] [Reconstruction loss: 0.082504] [Cotent loss: 0.000212]\n",
      "[Epoch 18/150] [Reconstruction loss: 0.082623] [Cotent loss: 0.000181]\n",
      "[Epoch 19/150] [Reconstruction loss: 0.081238] [Cotent loss: 0.000163]\n",
      "[Epoch 20/150] [Reconstruction loss: 0.083185] [Cotent loss: 0.000150]\n",
      "[Epoch 21/150] [Reconstruction loss: 0.081560] [Cotent loss: 0.000173]\n",
      "[Epoch 22/150] [Reconstruction loss: 0.079943] [Cotent loss: 0.000228]\n",
      "[Epoch 23/150] [Reconstruction loss: 0.082283] [Cotent loss: 0.000106]\n",
      "[Epoch 24/150] [Reconstruction loss: 0.080821] [Cotent loss: 0.000116]\n",
      "[Epoch 25/150] [Reconstruction loss: 0.081182] [Cotent loss: 0.000131]\n",
      "[Epoch 26/150] [Reconstruction loss: 0.083715] [Cotent loss: 0.000118]\n",
      "[Epoch 27/150] [Reconstruction loss: 0.082715] [Cotent loss: 0.000238]\n",
      "[Epoch 28/150] [Reconstruction loss: 0.080550] [Cotent loss: 0.000114]\n",
      "[Epoch 29/150] [Reconstruction loss: 0.078234] [Cotent loss: 0.000097]\n",
      "[Epoch 30/150] [Reconstruction loss: 0.076656] [Cotent loss: 0.000126]\n",
      "[Epoch 31/150] [Reconstruction loss: 0.077108] [Cotent loss: 0.000113]\n",
      "[Epoch 32/150] [Reconstruction loss: 0.074911] [Cotent loss: 0.000119]\n",
      "[Epoch 33/150] [Reconstruction loss: 0.077682] [Cotent loss: 0.000129]\n",
      "[Epoch 34/150] [Reconstruction loss: 0.076585] [Cotent loss: 0.000155]\n",
      "[Epoch 35/150] [Reconstruction loss: 0.075770] [Cotent loss: 0.000213]\n",
      "[Epoch 36/150] [Reconstruction loss: 0.076713] [Cotent loss: 0.000145]\n",
      "[Epoch 37/150] [Reconstruction loss: 0.078429] [Cotent loss: 0.000148]\n",
      "[Epoch 38/150] [Reconstruction loss: 0.075441] [Cotent loss: 0.000162]\n",
      "[Epoch 39/150] [Reconstruction loss: 0.075653] [Cotent loss: 0.000207]\n",
      "[Epoch 40/150] [Reconstruction loss: 0.073590] [Cotent loss: 0.000136]\n",
      "[Epoch 41/150] [Reconstruction loss: 0.075107] [Cotent loss: 0.000148]\n",
      "[Epoch 42/150] [Reconstruction loss: 0.075231] [Cotent loss: 0.000200]\n",
      "[Epoch 43/150] [Reconstruction loss: 0.072343] [Cotent loss: 0.000162]\n",
      "[Epoch 44/150] [Reconstruction loss: 0.075978] [Cotent loss: 0.000229]\n",
      "[Epoch 45/150] [Reconstruction loss: 0.073428] [Cotent loss: 0.000171]\n",
      "[Epoch 46/150] [Reconstruction loss: 0.072520] [Cotent loss: 0.000137]\n",
      "[Epoch 47/150] [Reconstruction loss: 0.072295] [Cotent loss: 0.000145]\n",
      "[Epoch 48/150] [Reconstruction loss: 0.071855] [Cotent loss: 0.000115]\n",
      "[Epoch 49/150] [Reconstruction loss: 0.074573] [Cotent loss: 0.000197]\n",
      "[Epoch 50/150] [Reconstruction loss: 0.072678] [Cotent loss: 0.000114]\n",
      "[Epoch 51/150] [Reconstruction loss: 0.071576] [Cotent loss: 0.000097]\n",
      "[Epoch 52/150] [Reconstruction loss: 0.070256] [Cotent loss: 0.000100]\n",
      "[Epoch 53/150] [Reconstruction loss: 0.069225] [Cotent loss: 0.000101]\n",
      "[Epoch 54/150] [Reconstruction loss: 0.070121] [Cotent loss: 0.000179]\n",
      "[Epoch 55/150] [Reconstruction loss: 0.072739] [Cotent loss: 0.000112]\n",
      "[Epoch 56/150] [Reconstruction loss: 0.070799] [Cotent loss: 0.000093]\n",
      "[Epoch 57/150] [Reconstruction loss: 0.070918] [Cotent loss: 0.000107]\n",
      "[Epoch 58/150] [Reconstruction loss: 0.072719] [Cotent loss: 0.000133]\n",
      "[Epoch 59/150] [Reconstruction loss: 0.073315] [Cotent loss: 0.000088]\n",
      "[Epoch 60/150] [Reconstruction loss: 0.069149] [Cotent loss: 0.000094]\n",
      "[Epoch 61/150] [Reconstruction loss: 0.070478] [Cotent loss: 0.000102]\n",
      "[Epoch 62/150] [Reconstruction loss: 0.068510] [Cotent loss: 0.000119]\n",
      "[Epoch 63/150] [Reconstruction loss: 0.069145] [Cotent loss: 0.000117]\n",
      "[Epoch 64/150] [Reconstruction loss: 0.071139] [Cotent loss: 0.000107]\n",
      "[Epoch 65/150] [Reconstruction loss: 0.070529] [Cotent loss: 0.000082]\n",
      "[Epoch 66/150] [Reconstruction loss: 0.072309] [Cotent loss: 0.000081]\n",
      "[Epoch 67/150] [Reconstruction loss: 0.070619] [Cotent loss: 0.000103]\n",
      "[Epoch 68/150] [Reconstruction loss: 0.069627] [Cotent loss: 0.000146]\n",
      "[Epoch 69/150] [Reconstruction loss: 0.071914] [Cotent loss: 0.000136]\n",
      "[Epoch 70/150] [Reconstruction loss: 0.068757] [Cotent loss: 0.000091]\n",
      "[Epoch 71/150] [Reconstruction loss: 0.068739] [Cotent loss: 0.000088]\n",
      "[Epoch 72/150] [Reconstruction loss: 0.068382] [Cotent loss: 0.000070]\n",
      "[Epoch 73/150] [Reconstruction loss: 0.070463] [Cotent loss: 0.000090]\n",
      "[Epoch 74/150] [Reconstruction loss: 0.068058] [Cotent loss: 0.000114]\n",
      "[Epoch 75/150] [Reconstruction loss: 0.070544] [Cotent loss: 0.000131]\n",
      "[Epoch 76/150] [Reconstruction loss: 0.071254] [Cotent loss: 0.000084]\n",
      "[Epoch 77/150] [Reconstruction loss: 0.067527] [Cotent loss: 0.000098]\n",
      "[Epoch 78/150] [Reconstruction loss: 0.070027] [Cotent loss: 0.000105]\n",
      "[Epoch 79/150] [Reconstruction loss: 0.068494] [Cotent loss: 0.000117]\n",
      "[Epoch 80/150] [Reconstruction loss: 0.067217] [Cotent loss: 0.000131]\n",
      "[Epoch 81/150] [Reconstruction loss: 0.068081] [Cotent loss: 0.000112]\n",
      "[Epoch 82/150] [Reconstruction loss: 0.067817] [Cotent loss: 0.000137]\n",
      "[Epoch 83/150] [Reconstruction loss: 0.068606] [Cotent loss: 0.000119]\n",
      "[Epoch 84/150] [Reconstruction loss: 0.066830] [Cotent loss: 0.000144]\n",
      "[Epoch 85/150] [Reconstruction loss: 0.066745] [Cotent loss: 0.000106]\n",
      "[Epoch 86/150] [Reconstruction loss: 0.068272] [Cotent loss: 0.000123]\n",
      "[Epoch 87/150] [Reconstruction loss: 0.067534] [Cotent loss: 0.000097]\n",
      "[Epoch 88/150] [Reconstruction loss: 0.068697] [Cotent loss: 0.000115]\n",
      "[Epoch 89/150] [Reconstruction loss: 0.066814] [Cotent loss: 0.000104]\n",
      "[Epoch 90/150] [Reconstruction loss: 0.067084] [Cotent loss: 0.000098]\n",
      "[Epoch 91/150] [Reconstruction loss: 0.068932] [Cotent loss: 0.000116]\n",
      "[Epoch 92/150] [Reconstruction loss: 0.067972] [Cotent loss: 0.000105]\n",
      "[Epoch 93/150] [Reconstruction loss: 0.066837] [Cotent loss: 0.000116]\n",
      "[Epoch 94/150] [Reconstruction loss: 0.068726] [Cotent loss: 0.000130]\n",
      "[Epoch 95/150] [Reconstruction loss: 0.067266] [Cotent loss: 0.000114]\n",
      "[Epoch 96/150] [Reconstruction loss: 0.067983] [Cotent loss: 0.000133]\n",
      "[Epoch 97/150] [Reconstruction loss: 0.065413] [Cotent loss: 0.000096]\n",
      "[Epoch 98/150] [Reconstruction loss: 0.065431] [Cotent loss: 0.000092]\n",
      "[Epoch 99/150] [Reconstruction loss: 0.066545] [Cotent loss: 0.000111]\n",
      "[Epoch 100/150] [Reconstruction loss: 0.068442] [Cotent loss: 0.000093]\n",
      "[Epoch 101/150] [Reconstruction loss: 0.066847] [Cotent loss: 0.000127]\n",
      "[Epoch 102/150] [Reconstruction loss: 0.066593] [Cotent loss: 0.000116]\n",
      "[Epoch 103/150] [Reconstruction loss: 0.066111] [Cotent loss: 0.000096]\n",
      "[Epoch 104/150] [Reconstruction loss: 0.067731] [Cotent loss: 0.000151]\n",
      "[Epoch 105/150] [Reconstruction loss: 0.067474] [Cotent loss: 0.000090]\n",
      "[Epoch 106/150] [Reconstruction loss: 0.066524] [Cotent loss: 0.000115]\n",
      "[Epoch 107/150] [Reconstruction loss: 0.064621] [Cotent loss: 0.000130]\n",
      "[Epoch 108/150] [Reconstruction loss: 0.068283] [Cotent loss: 0.000100]\n",
      "[Epoch 109/150] [Reconstruction loss: 0.069193] [Cotent loss: 0.000111]\n",
      "[Epoch 110/150] [Reconstruction loss: 0.067739] [Cotent loss: 0.000104]\n",
      "[Epoch 111/150] [Reconstruction loss: 0.065087] [Cotent loss: 0.000135]\n",
      "[Epoch 112/150] [Reconstruction loss: 0.064837] [Cotent loss: 0.000107]\n",
      "[Epoch 113/150] [Reconstruction loss: 0.066284] [Cotent loss: 0.000099]\n",
      "[Epoch 114/150] [Reconstruction loss: 0.066691] [Cotent loss: 0.000124]\n",
      "[Epoch 115/150] [Reconstruction loss: 0.065312] [Cotent loss: 0.000124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 116/150] [Reconstruction loss: 0.066052] [Cotent loss: 0.000134]\n",
      "[Epoch 117/150] [Reconstruction loss: 0.064400] [Cotent loss: 0.000151]\n",
      "[Epoch 118/150] [Reconstruction loss: 0.064230] [Cotent loss: 0.000134]\n",
      "[Epoch 119/150] [Reconstruction loss: 0.065906] [Cotent loss: 0.000130]\n",
      "[Epoch 120/150] [Reconstruction loss: 0.067301] [Cotent loss: 0.000157]\n",
      "[Epoch 121/150] [Reconstruction loss: 0.065921] [Cotent loss: 0.000141]\n",
      "[Epoch 122/150] [Reconstruction loss: 0.063355] [Cotent loss: 0.000119]\n",
      "[Epoch 123/150] [Reconstruction loss: 0.064630] [Cotent loss: 0.000142]\n",
      "[Epoch 124/150] [Reconstruction loss: 0.063344] [Cotent loss: 0.000107]\n",
      "[Epoch 125/150] [Reconstruction loss: 0.065022] [Cotent loss: 0.000086]\n",
      "[Epoch 126/150] [Reconstruction loss: 0.062767] [Cotent loss: 0.000108]\n",
      "[Epoch 127/150] [Reconstruction loss: 0.065979] [Cotent loss: 0.000127]\n",
      "[Epoch 128/150] [Reconstruction loss: 0.065551] [Cotent loss: 0.000091]\n",
      "[Epoch 129/150] [Reconstruction loss: 0.063862] [Cotent loss: 0.000104]\n",
      "[Epoch 130/150] [Reconstruction loss: 0.064987] [Cotent loss: 0.000117]\n",
      "[Epoch 131/150] [Reconstruction loss: 0.064820] [Cotent loss: 0.000133]\n",
      "[Epoch 132/150] [Reconstruction loss: 0.063816] [Cotent loss: 0.000110]\n",
      "[Epoch 133/150] [Reconstruction loss: 0.063759] [Cotent loss: 0.000131]\n",
      "[Epoch 134/150] [Reconstruction loss: 0.064024] [Cotent loss: 0.000109]\n",
      "[Epoch 135/150] [Reconstruction loss: 0.066384] [Cotent loss: 0.000095]\n",
      "[Epoch 136/150] [Reconstruction loss: 0.063249] [Cotent loss: 0.000103]\n",
      "[Epoch 137/150] [Reconstruction loss: 0.065078] [Cotent loss: 0.000106]\n",
      "[Epoch 138/150] [Reconstruction loss: 0.064789] [Cotent loss: 0.000116]\n",
      "[Epoch 139/150] [Reconstruction loss: 0.063223] [Cotent loss: 0.000104]\n",
      "[Epoch 140/150] [Reconstruction loss: 0.063047] [Cotent loss: 0.000116]\n",
      "[Epoch 141/150] [Reconstruction loss: 0.062576] [Cotent loss: 0.000121]\n",
      "[Epoch 142/150] [Reconstruction loss: 0.065794] [Cotent loss: 0.000112]\n",
      "[Epoch 143/150] [Reconstruction loss: 0.067973] [Cotent loss: 0.000125]\n",
      "[Epoch 144/150] [Reconstruction loss: 0.061990] [Cotent loss: 0.000118]\n",
      "[Epoch 145/150] [Reconstruction loss: 0.064389] [Cotent loss: 0.000110]\n",
      "[Epoch 146/150] [Reconstruction loss: 0.064479] [Cotent loss: 0.000131]\n",
      "[Epoch 147/150] [Reconstruction loss: 0.064023] [Cotent loss: 0.000135]\n",
      "[Epoch 148/150] [Reconstruction loss: 0.063336] [Cotent loss: 0.000191]\n",
      "[Epoch 149/150] [Reconstruction loss: 0.065597] [Cotent loss: 0.000144]\n",
      "[Epoch 150/150] [Reconstruction loss: 0.062563] [Cotent loss: 0.000174]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Blending with GAN...\n",
      "Adata Info: \n",
      "AnnData object with n_obs × n_vars = 656258 × 1615\n",
      "    obs: 'batch', 'n_genes', 'n_counts'\n",
      "    var: 'gene_ids', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
      "    uns: 'log1p'\n",
      "Orders: 1<-0\n",
      "Merging dataset 0 to 1\n",
      "Calculating Anchor Pairs...\n",
      "Calculating Query Pairs...\n",
      "Calculating KNN Pairs...\n",
      "Calculating Random Walk Pairs...\n",
      "Done.\n",
      "[Epoch 1/100] [D loss: 0.412074] [G loss: 0.034719]\n",
      "[Epoch 2/100] [D loss: -5.262790] [G loss: 3.118864]\n",
      "[Epoch 3/100] [D loss: -5.857967] [G loss: 7.958799]\n",
      "[Epoch 4/100] [D loss: -5.441822] [G loss: 8.134035]\n",
      "[Epoch 5/100] [D loss: -4.440301] [G loss: 6.950170]\n",
      "[Epoch 6/100] [D loss: -3.361588] [G loss: 5.555587]\n",
      "[Epoch 7/100] [D loss: -2.701076] [G loss: 4.142798]\n",
      "[Epoch 8/100] [D loss: -2.148527] [G loss: 3.164813]\n",
      "[Epoch 9/100] [D loss: -1.816118] [G loss: 2.432121]\n",
      "[Epoch 10/100] [D loss: -1.718375] [G loss: 1.846512]\n",
      "[Epoch 11/100] [D loss: -1.590038] [G loss: 1.512416]\n",
      "[Epoch 12/100] [D loss: -1.519300] [G loss: 1.413413]\n",
      "[Epoch 13/100] [D loss: -1.478499] [G loss: 1.681008]\n",
      "[Epoch 14/100] [D loss: -1.353236] [G loss: 1.853209]\n",
      "[Epoch 15/100] [D loss: -1.291614] [G loss: 2.009127]\n",
      "[Epoch 16/100] [D loss: -1.291501] [G loss: 2.159768]\n",
      "[Epoch 17/100] [D loss: -1.341100] [G loss: 2.362088]\n",
      "[Epoch 18/100] [D loss: -1.142124] [G loss: 2.189951]\n",
      "[Epoch 19/100] [D loss: -1.234841] [G loss: 1.928146]\n",
      "[Epoch 20/100] [D loss: -1.299644] [G loss: 1.679499]\n",
      "[Epoch 21/100] [D loss: -1.288927] [G loss: 1.430279]\n",
      "[Epoch 22/100] [D loss: -1.363728] [G loss: 1.613872]\n",
      "[Epoch 23/100] [D loss: -1.429889] [G loss: 1.562618]\n",
      "[Epoch 24/100] [D loss: -1.333663] [G loss: 1.292686]\n",
      "[Epoch 25/100] [D loss: -1.413086] [G loss: 1.172604]\n",
      "[Epoch 26/100] [D loss: -1.532080] [G loss: 1.181700]\n",
      "[Epoch 27/100] [D loss: -1.655349] [G loss: 1.062973]\n",
      "[Epoch 28/100] [D loss: -1.743643] [G loss: 0.996029]\n",
      "[Epoch 29/100] [D loss: -1.848219] [G loss: 0.469156]\n",
      "[Epoch 30/100] [D loss: -2.001357] [G loss: 0.456439]\n",
      "[Epoch 31/100] [D loss: -2.102579] [G loss: 1.235623]\n",
      "[Epoch 32/100] [D loss: -2.234768] [G loss: 0.374368]\n",
      "[Epoch 33/100] [D loss: -2.289672] [G loss: 0.135308]\n",
      "[Epoch 34/100] [D loss: -2.348325] [G loss: 0.495341]\n",
      "[Epoch 35/100] [D loss: -2.403653] [G loss: 0.098589]\n",
      "[Epoch 36/100] [D loss: -2.496586] [G loss: 0.366172]\n",
      "[Epoch 37/100] [D loss: -2.601058] [G loss: 0.120089]\n",
      "[Epoch 38/100] [D loss: -2.490199] [G loss: -0.599355]\n",
      "[Epoch 39/100] [D loss: -2.657220] [G loss: -0.322634]\n",
      "[Epoch 40/100] [D loss: -2.815778] [G loss: 0.432206]\n",
      "[Epoch 41/100] [D loss: -2.715278] [G loss: -0.501713]\n",
      "[Epoch 42/100] [D loss: -2.617116] [G loss: 0.057554]\n",
      "[Epoch 43/100] [D loss: -2.907145] [G loss: 0.522647]\n",
      "[Epoch 44/100] [D loss: -2.685605] [G loss: -0.544049]\n",
      "[Epoch 45/100] [D loss: -2.773220] [G loss: 0.312574]\n",
      "[Epoch 46/100] [D loss: -2.892066] [G loss: -0.047647]\n",
      "[Epoch 47/100] [D loss: -2.774381] [G loss: -0.161347]\n",
      "[Epoch 48/100] [D loss: -2.922478] [G loss: -0.455688]\n",
      "[Epoch 49/100] [D loss: -2.919038] [G loss: 0.315183]\n",
      "[Epoch 50/100] [D loss: -3.040493] [G loss: 0.019060]\n",
      "[Epoch 51/100] [D loss: -2.920724] [G loss: 0.031665]\n",
      "[Epoch 52/100] [D loss: -2.844908] [G loss: -0.330615]\n",
      "[Epoch 53/100] [D loss: -2.968904] [G loss: 0.379297]\n",
      "[Epoch 54/100] [D loss: -2.894680] [G loss: 0.223630]\n",
      "[Epoch 55/100] [D loss: -3.005403] [G loss: -0.053648]\n",
      "[Epoch 56/100] [D loss: -2.781334] [G loss: -0.704761]\n",
      "[Epoch 57/100] [D loss: -2.860354] [G loss: -0.314206]\n",
      "[Epoch 58/100] [D loss: -2.882048] [G loss: 0.428794]\n",
      "[Epoch 59/100] [D loss: -2.856725] [G loss: 0.353810]\n",
      "[Epoch 60/100] [D loss: -2.956421] [G loss: 0.455665]\n",
      "[Epoch 61/100] [D loss: -3.068906] [G loss: -0.165874]\n",
      "[Epoch 62/100] [D loss: -3.141181] [G loss: -0.502741]\n",
      "[Epoch 63/100] [D loss: -3.025033] [G loss: -0.236488]\n",
      "[Epoch 64/100] [D loss: -2.775617] [G loss: 0.390050]\n",
      "[Epoch 65/100] [D loss: -3.077832] [G loss: 0.381537]\n",
      "[Epoch 66/100] [D loss: -2.965454] [G loss: 0.038501]\n",
      "[Epoch 67/100] [D loss: -2.938335] [G loss: 0.191805]\n",
      "[Epoch 68/100] [D loss: -2.774455] [G loss: -0.461101]\n",
      "[Epoch 69/100] [D loss: -2.871598] [G loss: -0.437849]\n",
      "[Epoch 70/100] [D loss: -2.953087] [G loss: -0.394438]\n",
      "[Epoch 71/100] [D loss: -2.843153] [G loss: -0.467266]\n",
      "[Epoch 72/100] [D loss: -2.856238] [G loss: 0.533521]\n",
      "[Epoch 73/100] [D loss: -2.906185] [G loss: 0.045932]\n",
      "[Epoch 74/100] [D loss: -2.881309] [G loss: -0.524719]\n",
      "[Epoch 75/100] [D loss: -2.906340] [G loss: 0.036476]\n",
      "[Epoch 76/100] [D loss: -2.797136] [G loss: -0.322415]\n",
      "[Epoch 77/100] [D loss: -2.820169] [G loss: -0.305661]\n",
      "[Epoch 78/100] [D loss: -2.936920] [G loss: -0.249687]\n",
      "[Epoch 79/100] [D loss: -2.803569] [G loss: -0.421845]\n",
      "[Epoch 80/100] [D loss: -2.977804] [G loss: -0.948735]\n",
      "[Epoch 81/100] [D loss: -2.715727] [G loss: -0.302064]\n",
      "[Epoch 82/100] [D loss: -2.706462] [G loss: 0.206988]\n",
      "[Epoch 83/100] [D loss: -2.769253] [G loss: -0.487895]\n",
      "[Epoch 84/100] [D loss: -2.773485] [G loss: -0.429023]\n",
      "[Epoch 85/100] [D loss: -2.834007] [G loss: -0.527318]\n",
      "[Epoch 86/100] [D loss: -2.623516] [G loss: -0.439258]\n",
      "[Epoch 87/100] [D loss: -2.838557] [G loss: -0.444781]\n",
      "[Epoch 88/100] [D loss: -2.790119] [G loss: -0.068906]\n",
      "[Epoch 89/100] [D loss: -2.781991] [G loss: -0.068295]\n",
      "[Epoch 90/100] [D loss: -2.691978] [G loss: 0.072732]\n",
      "[Epoch 91/100] [D loss: -2.687057] [G loss: -0.171273]\n",
      "[Epoch 92/100] [D loss: -2.695536] [G loss: -0.896727]\n",
      "[Epoch 93/100] [D loss: -2.674274] [G loss: -0.717911]\n",
      "[Epoch 94/100] [D loss: -2.584595] [G loss: -0.386971]\n",
      "[Epoch 95/100] [D loss: -2.793906] [G loss: -0.720482]\n",
      "[Epoch 96/100] [D loss: -2.731296] [G loss: -0.039691]\n",
      "[Epoch 97/100] [D loss: -2.534570] [G loss: -0.426427]\n",
      "[Epoch 98/100] [D loss: -2.582759] [G loss: -0.451007]\n",
      "[Epoch 99/100] [D loss: -2.590763] [G loss: 0.268634]\n",
      "[Epoch 100/100] [D loss: -2.576669] [G loss: -0.329900]\n",
      "195\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "### Stage I\n",
    "EC, ec_data = imap.iMAP_fast(adata, key=\"batch\", n_epochs=150) \n",
    "### Stage II\n",
    "output_results = utils.integrate_data(adata, ec_data, n_epochs=100)\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "print((endtime-starttime).seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizations for the final output results**:The results are saved in './pic/' directory. \n",
    "    \n",
    "Due to the large number of cells in 'human cell atlas' dataset. The cost of time is usually around 1710s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "\n",
    "#### UMAP ####\n",
    "def data2umap(data, n_pca=0):\n",
    "    if n_pca > 0:\n",
    "        pca = PCA(n_components=n_pca)\n",
    "        embedding = pca.fit_transform(data)\n",
    "    else:\n",
    "        embedding = data\n",
    "    embedding_ = umap.UMAP(\n",
    "        n_neighbors=30,\n",
    "        min_dist=0.3,\n",
    "        metric='cosine',\n",
    "        n_components = 2,\n",
    "        learning_rate = 1.0,\n",
    "        spread = 1.0,\n",
    "        set_op_mix_ratio = 1.0,\n",
    "        local_connectivity = 1,\n",
    "        repulsion_strength = 1,\n",
    "        negative_sample_rate = 5,\n",
    "        angular_rp_forest = False,\n",
    "        verbose = False\n",
    "    ).fit_transform(embedding)\n",
    "    return embedding_\n",
    "def umap_plot(data, hue, title, save_path):\n",
    "    import seaborn as sns\n",
    "    fig = sns.lmplot(\n",
    "        x = 'UMAP_1',\n",
    "        y = 'UMAP_2',\n",
    "        data = data,\n",
    "        fit_reg = False,\n",
    "        legend = True,\n",
    "        size = 9,\n",
    "        hue = hue,\n",
    "        scatter_kws = {'s':4, \"alpha\":0.6}\n",
    "    )\n",
    "    plt.title(title, weight='bold').set_fontsize('20')\n",
    "    fig.savefig(save_path)\n",
    "    plt.close()\n",
    "def gplot(embedding_, batch_info, celltype_info, filename):\n",
    "    test = pd.DataFrame(embedding_, columns=['UMAP_1', 'UMAP_2'])\n",
    "    test['Label1'] = batch_info\n",
    "    test['Label2'] = celltype_info\n",
    "    title = f' '\n",
    "    for i in range(1,3):\n",
    "        hue = f'Label{i}'\n",
    "        save_path = './pic/'+filename + f'{i}.png'\n",
    "        umap_plot(test, hue, title, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "embedding_ = data2umap(output_results, n_pca=30)\n",
    "gplot(embedding_, np.array(adata.obs['batch']), np.array(adata.obs['batch']), 'human_cell_atlas_G_')\n",
    "endtime = datetime.datetime.now()\n",
    "print((endtime-starttime).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
