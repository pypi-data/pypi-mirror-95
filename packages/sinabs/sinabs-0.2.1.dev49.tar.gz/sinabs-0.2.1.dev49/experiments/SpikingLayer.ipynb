{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sinabs.layers.functional import threshold_subtract, threshold_reset \n",
    "from sinabs.layers import Layer\n",
    "# - Type alias for array-like objects\n",
    "from typing import Optional, Union, List, Tuple\n",
    "ArrayLike = Union[np.ndarray, List, Tuple]\n",
    "from abc import abstractmethod\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinabs.layers.iaf_bptt import SpikingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeSomaLayer(SpikingLayer):\n",
    "    def synaptic_output(self, input_current: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        This method needs to be overridden/defined by the child class\n",
    "\n",
    "        :param input_spikes: torch.Tensor input to the layer.\n",
    "        :return:  torch.Tensor - synaptic output current\n",
    "        \"\"\"\n",
    "        return input_current\n",
    "    \n",
    "    def get_output_shape(self, in_shape):\n",
    "        return in_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, n_inp=28, n_neurons=100, n_out=10, decay=0.8):\n",
    "        super().__init__()\n",
    "        self.n_inp = n_inp\n",
    "        self.n_neurons = n_neurons\n",
    "        self.n_out = n_out\n",
    "        self.v_th = 1.0\n",
    "        # Feed forward input\n",
    "        self.inp_linear = nn.Linear(n_inp, n_neurons, bias=False)\n",
    "        # Recurrent pool of neurons\n",
    "        self.rec = nn.Linear(n_neurons, n_neurons, bias=False)\n",
    "        self.rec_neurons = SpikeSomaLayer(input_shape=n_neurons)\n",
    "        # Feedforward output\n",
    "        self.out_linear = nn.Linear(n_neurons, n_out, bias=False)\n",
    "        self.out_neurons = SpikeSomaLayer(input_shape=n_out)\n",
    "        self.init_states()\n",
    "\n",
    "    def init_states(self, randomize=True, batch_size=1):\n",
    "        self.rec_neurons.reset_states(shape=(batch_size,self.n_neurons))\n",
    "        self.out_neurons.reset_states(shape=(batch_size, self.n_out))\n",
    "\n",
    "    def forward(self, inp) -> (torch.Tensor, torch.Tensor):\n",
    "        activations = self.rec_neurons.activations\n",
    "        # all_rec_spikes = []\n",
    "        all_out_spikes = []\n",
    "        for row in range(inp.shape[1]):\n",
    "            # Readout layer\n",
    "            out_linear = self.out_linear(activations)\n",
    "            out = self.out_neurons(out_linear.unsqueeze(0)).squeeze(0)\n",
    "            assert out.shape == (128, 10)\n",
    "            all_out_spikes.append(out)\n",
    "            # Recurrent input\n",
    "            recurrent_inputs = self.rec(activations)  # Recurrent input\n",
    "            # Input activations\n",
    "            input_ext = self.inp_linear(inp[:, row])  # External input\n",
    "            activations = self.rec_neurons(\n",
    "                (input_ext + recurrent_inputs).unsqueeze(0)\n",
    "            ).squeeze(0)  # recurrent spiking neuron output\n",
    "\n",
    "        all_out_spikes = torch.stack(all_out_spikes).transpose(0,1)\n",
    "\n",
    "        return all_out_spikes.sum(1), all_out_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    with torch.no_grad():\n",
    "        accuracy = 100 * (torch.argmax(preds, 1) == labels).float().sum() / len(labels)\n",
    "    return accuracy.detach().item()\n",
    "\n",
    "\n",
    "def binarize(data):\n",
    "    return (data > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from datetime import datetime\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 20\n",
    "n_neurons = 512\n",
    "decay = 1.0\n",
    "\n",
    "randomize_vmem = True\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root=\"./\", train=False, download=True)\n",
    "device = (\n",
    "    torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "# Convert to tensor and binarize them\n",
    "transform = transforms.Compose([transforms.ToTensor(), binarize, torch.squeeze])\n",
    "\n",
    "# Download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True\n",
    ")\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=8, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = MyRNN(n_neurons=n_neurons, decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe62cb6adb4a437a919d7a754fb0e3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Training parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=1e-4)\n",
    "\n",
    "# try:\n",
    "#    params = torch.load(\"trained/srnn_mnist_19-09-14-22:09.pt\")\n",
    "#    rnn.load_state_dict(params['model_state_dict'])\n",
    "# except FileNotFoundError as e:\n",
    "#    pass\n",
    "rnn.to(device)\n",
    "\n",
    "# Log data of the experiment\n",
    "writer = SummaryWriter()\n",
    "save_path = writer.get_logdir()\n",
    "\n",
    "pbar_epoch = tqdm(range(n_epochs))\n",
    "for epoch in pbar_epoch:\n",
    "    running_loss = 0\n",
    "    running_accuracy = []\n",
    "\n",
    "    # Training dataset\n",
    "    for data in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        rnn.init_states(randomize=randomize_vmem, batch_size=batch_size)\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        out, _ = rnn(imgs)\n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_accuracy.append(accuracy(out, labels))\n",
    "\n",
    "        running_loss += loss.detach().item()\n",
    "\n",
    "    # Test dataset\n",
    "    with torch.no_grad():\n",
    "        test_accuracy = []\n",
    "        for data in testloader:\n",
    "            rnn.init_states(randomize=randomize_vmem, batch_size=batch_size)\n",
    "            imgs, labels = data\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            out, spikes_out = rnn(imgs)\n",
    "            test_accuracy.append(accuracy(out, labels))\n",
    "\n",
    "        pbar_epoch.set_postfix(\n",
    "            loss=loss.item(),\n",
    "            weights=[p.abs().mean().item() for p in rnn.parameters()],\n",
    "            train_accuracy=np.mean(running_accuracy),\n",
    "            test_accuracy=np.mean(test_accuracy),\n",
    "        )\n",
    "\n",
    "        params = list(rnn.parameters())\n",
    "        writer.add_scalars(\n",
    "            \"Accuracy\",\n",
    "            {\"train\": np.mean(running_accuracy), \"test\": np.mean(test_accuracy)},\n",
    "            epoch,\n",
    "        )\n",
    "        writer.add_scalar(\"Weight/Input\", params[0].abs().mean().item(), epoch)\n",
    "        writer.add_scalar(\"Weight/Recurrent\", params[1].abs().mean().item(), epoch)\n",
    "        writer.add_scalar(\"Weight/Output\", params[2].abs().mean().item(), epoch)\n",
    "        writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
