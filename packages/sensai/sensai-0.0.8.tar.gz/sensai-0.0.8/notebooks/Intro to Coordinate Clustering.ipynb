{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Coordinate Clustering Module\n",
    "\n",
    "On top of support for different clustering algorithms, sensAI provides useful methods specific to\n",
    "clustering of geospatial data. They include utilities for wrangling geometrical data, spanning trees and for persisting and\n",
    "visualizing the results. It seamlessly interoperates with geopandas and shapely.\n",
    "This notebook gives an overview of the coordinate clustering's main functions\n",
    "\n",
    "\n",
    "## Before running the notebook\n",
    "\n",
    "Install the library and its dependencies with, if you haven't done so already\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "from the root directory. You can also execute this command directly in the notebook but will need to reload the\n",
    "kernel afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - this cell should be executed only once per session\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# in order to get the config, it is not part of the library\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.path.abspath(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gp\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import logging\n",
    "from sensai.util.graph import CoordinateSpanningTree\n",
    "from sensai.clustering.coordinate_clustering import SKLearnCoordinateClustering\n",
    "from sensai.util.geometry import alphaShape\n",
    "from config import get_config\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "c = get_config(reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The library contains utils for loading coordinates from files and for wrapping arbitrary scikit-learn compatible\n",
    "clustering algorithms. Custom clustering algorithms can be implemented easily buy inheriting from the baseclass\n",
    "`ClusteringModel`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleFile = c.datafile_path(\"sample\", stage=c.RAW) # this can point to a directory or a shp/geojson file\n",
    "sampleGeoDF = gp.read_file(sampleFile)\n",
    "dbscan = SKLearnCoordinateClustering(DBSCAN(eps=150, min_samples=20))\n",
    "dbscan.fit(sampleGeoDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `CoordinateClusteringAlgorithm` instance has many useful methods.\n",
    "You can retrieve clusters individually or via a generator. The noise cluster can be accessed individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Clusters found: {dbscan.numClusters}\")\n",
    "\n",
    "clustersMin50 = list(dbscan.clusters(condition=lambda x: len(x) >= 50))\n",
    "\n",
    "print(f\"Clusters with at least 50 members: {len(clustersMin50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dbscan single clusters which are instances of `CoordinateClusteringAlgorithm.Cluster` \n",
    "can be retrieved and visualized. Most objects, including the dbscan itself, have an inbuilt plot method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.plot(markersize=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can condition before plotting as well as pass custom arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.plot(condition=lambda x: len(x) >= 50, cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of a single cluster\n",
    "\n",
    "Single clusters can be plotted too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleCluster = dbscan.getCluster(0)\n",
    "\n",
    "sampleCluster.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters have an identifier and coordinates. It is easy to extract additional information,\n",
    "e.g. via the summary method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(sampleCluster.summaryDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A single cluster is just a wrapper around its coordinates. They can be\n",
    "retrieved either as a numpy array, a geodataframe or a MultiPoint object.\n",
    "The latter is useful for geometric operations, e.g. computing hulls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusterMultipoint = sampleCluster.asMultipoint()\n",
    "clusterMultipoint.convex_hull"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we also provide a utility for computing alpha shapes for such objects\n",
    "\n",
    "alphaShape(clusterMultipoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sensAI also provides utilities for computing trees, e.g. here for the minimal spanning tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampleTree = CoordinateSpanningTree(sampleCluster)\n",
    "sampleTree.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most objects provide a way for extracting a summary from them, either as a dict or as a data frame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cluster summary:\")\n",
    "pprint(sampleCluster.summaryDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.summaryDF().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the objects used above can be exported to a GeoDataFrame using the `toGeoDF` method. This geodataframe\n",
    "can then be persisted as usual.\n",
    "\n",
    "In addition to that `CoordinateClusteringAlgorithm` has its own save method which persists the object as pickle.\n",
    "An instance can be loaded using the load classmethod.\n",
    "This way of persisting the fitted algorithm is _much more efficient and general_ than saving the corresponding gdf\n",
    "\n",
    "Individual clusters themselves also have saving and loading methods,\n",
    "with the difference that they are persisted as (and instantiated from) shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanGeoDF = dbscan.toGeoDF() # here again a condition for filtering clusters can be passed\n",
    "clusterGeoDF = sampleCluster.toGeoDF()\n",
    "treeGeoDF = sampleTree.toGeoDF()\n",
    "dbscanGeoDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscanSavedPath = os.path.join(c.temp, f\"{dbscan}_sample.pickle\")\n",
    "clusterSavedPath = os.path.join(c.temp, f\"sampleCluster_{sampleCluster.identifier}\")\n",
    "\n",
    "\n",
    "dbscan.save(dbscanSavedPath)\n",
    "sampleCluster.save(clusterSavedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedDBSCAN = SKLearnCoordinateClustering.load(dbscanSavedPath)\n",
    "loadedCluster = SKLearnCoordinateClustering.Cluster.load(clusterSavedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The loaded objects are equal to the ones we persisted\n",
    "\n",
    "print(loadedCluster.identifier == sampleCluster.identifier)\n",
    "print(np.array_equal(sampleCluster.datapoints, loadedDBSCAN.getCluster(0).datapoints))\n",
    "\n",
    "# Cleaning up\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(clusterSavedPath)\n",
    "os.remove(dbscanSavedPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}