
* get rid of the remaining conflict handler stuff

* add some tests for interleaved transactions

  - raise a specific Exception on a conflict (to be converted to Retry somewhere)

* performance optimizations:

  - now pjpersist does an INSERT and an UPDATE when adding an object,
    bring it down to one INSERT
    or one UPSERT

    ( in cases of people[None] = Person(u"name") )

  - think about how to batch SQL commands
    e.g. in `PJDataManager._flush_objects`

  - get rid of `persistence_name_map` and always store the class,

  - move the field `PY_TYPE_ATTR_NAME` out from the JSONB data to a real column
    (would avoid a `state_doc = copy.deepcopy(doc)` where deepcopy is expensive)

    adamG: this does help a little, but is not significant

    second thought: might not be so easy, because subobjects also get this field

  - think about implementing an object cache per connection and providing
    invalidation messages as ZEO (and maybe relstorage? does)
    see ZODB / collaborations.txt

  - use ujson instead of the built-in json module:
    http://blog.hartleybrody.com/python-serialize/

    adamG: this does not help much at the moment, most of time is taken by
    cursor.execute

  - crazy idea: make UPDATEs and INSERTs async, wait for those async operations
    to complete before SELECTs and COMMIT
    IOW, do UPDATEs and INSERTs in a thread, join() the threads before SELECTs

  - sqlbuilder __sqlrepr__ is slow, use SQL commands whereever it is possible
    and makes sense
