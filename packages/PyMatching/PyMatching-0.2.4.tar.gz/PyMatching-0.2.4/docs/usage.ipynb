{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the functionality of PyMatching is available through the `pymatching.matching.Matching` class, which can be imported in Python with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatching import Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Matching` class is used to represent the $X$-type or $Z$-type matching graph of a CSS quantum code for which syndrome defects come in pairs (or in isolation at a boundary). Each edge in the matching graph corresponds to a single error, and each node corresponds to a stabiliser measurement (or a boundary). The simplest way to construct a `Matching` object is from the X or Z check matrix of the code, which can be given as a numpy or a scipy array. For example, we can construct the $Z$-type matching graph for a five-qubit quantum bit-flip repetition code (which has $Z$ stabilisers $ZZIII$, $IZZII$, $IIZZI$ and $IIIZZ$) from the $Z$ check matrix using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymatching.Matching object with 5 qubits, 4 stabilisers, 1 boundary node, and 5 edges>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Each column of Hz corresponds to a qubit, and each \n",
    "row corresponds to a Z stabiliser.\n",
    "\n",
    "Hz[i,j]==1 if Z stabiliser i acts non-trivially\n",
    "on qubit j, and is 0 otherwise.\n",
    "\"\"\"\n",
    "Hz = np.array([\n",
    "    [1,1,0,0,0],\n",
    "    [0,1,1,0,0],\n",
    "    [0,0,1,1,0],\n",
    "    [0,0,0,1,1]\n",
    "])\n",
    "\n",
    "m = Matching(Hz)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, since two qubits (0 and 4) are incident to only a single stabiliser, a boundary node has automatically been created in the matching graph, and is connected to the stabilisers acting non-trivially on qubits 0 and 4. The weights of all edges in the matching graph default to 1.0, unless they are specified using the `spacelike_weights` parameter.\n",
    "\n",
    "If $X$ errors occur on the third and fourth qubits we have a binary noise vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.array([0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the resulting syndrome vector is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "z = Hz@noise % 2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This syndrome vector `z` can then be decoded simply using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: [0 0 1 1 0], of type <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "c = m.decode(z)\n",
    "print(f\"c: {c}, of type {type(c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `c` is the $X$ correction operator (i.e. $IIXXI$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for larger check matrices you may instead prefer to use a scipy sparse matrix to represent the check matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymatching.Matching object with 5 qubits, 4 stabilisers, 1 boundary node, and 5 edges>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "Hz = scipy.sparse.csr_matrix(Hz)\n",
    "m = Matching(Hz)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Syndromes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacetime matching graph\n",
    "\n",
    "If stabiliser measurements are instead noisy, then each stabiliser measurement must be repeated, with each defect in the matching graph corresponding to a change in the syndrome (see IV B of [this paper](https://arxiv.org/abs/quant-ph/0110143)). We will repeat each stabiliser measurement 5 times, with each qubit suffering an $X$ error with probability `p`, and each stabiliser will be measured incorrectly with probability `q`. Spacelike edges will be weighted with $\\log((1-p)/p)$ and timelike edges will be weighted with $\\log((1-q)/q)$. The Matching object representing this spacetime matching graph can be constructed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions=5\n",
    "p = 0.05\n",
    "q = 0.05\n",
    "m2d = Matching(Hz, \n",
    "               spacelike_weights=np.log((1-p)/p),\n",
    "               repetitions=repetitions,\n",
    "               timelike_weights=np.log((1-q)/q)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate noisy syndromes\n",
    "\n",
    "Now if each qubit suffers an $X$ error with probability `p` in each round of stabiliser measurements, the errors on the data qubits can be given as a 2D numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_stabilisers, num_qubits = Hz.shape\n",
    "np.random.seed(1) # Keep RNG deterministic\n",
    "noise_new = (np.random.rand(num_qubits, repetitions) < p).astype(np.uint8)\n",
    "noise_new # New errors in each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_cumulative = (np.cumsum(noise_new, 1) % 2).astype(np.uint8)\n",
    "noise_total = noise_cumulative[:,-1] # Total cumulative noise at the last round\n",
    "noise_cumulative # Cumulative errors in each time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding noiseless syndrome would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_noiseless = Hz@noise_cumulative % 2\n",
    "z_noiseless # Noiseless syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume each syndrome measurement is incorrect with probability `q`, but that the last round of measurements is perfect to ensure an even number of defects (a simple approximation - the overlapping recovery method could be used in practice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_err = (np.random.rand(num_stabilisers, repetitions) < q).astype(np.uint8)\n",
    "z_err[:,-1] = 0\n",
    "z_err # Syndrome errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_noisy = (z_noiseless + z_err) % 2\n",
    "z_noisy # Noisy syndromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_noisy[:,1:] = (z_noisy[:,1:] - z_noisy[:,0:-1]) % 2\n",
    "z_noisy # Convert to difference syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode\n",
    "\n",
    "Decoding can now be done just by inputting this 2D syndrome vector to the `Matching.decode` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction = m2d.decode(z_noisy)\n",
    "correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see that this correction operator successfully corrects the cumulative total noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(noise_total + correction) % 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from NetworkX graphs\n",
    "\n",
    "While it can be convenient to decode directly from the check matrices, especially when simulating under a standard independent or phenomenological noise model, it is sometimes necessary to construct the matching graph nodes, edges, weights and boundaries explicitly. This is useful for decoding under more complicated (e.g. circuit-level) noise models, for which matching graph edges can be between nodes separated in both space and time (\"diagonal edges\"). There can also be so called \"hook errors\", which are single faults (matching graph edges) corresponding to errors on two or more qubits. Furthermore, the stabilisers themselves can change as a function of time when using schedule-induced gauge fixing of a subsystem code (see [this paper](https://arxiv.org/abs/2010.09626)).\n",
    "\n",
    "To provide the functionality to handle these use cases, PyMatching allows Matching objects to be constructed explicitly from [NetworkX](https://networkx.org/documentation/stable/index.html) graphs.\n",
    "\n",
    "Each node in the matching graph with $n$ nodes, represented by the `pymatching.Matching` object, should be uniquely identified by an integer between $0$ and $n-1$ (inclusive). Edges are then added between these integer nodes, with optional attributes `weight`, `qubit_id` and `error_probability`. \n",
    "\n",
    "We will again use the quantum repetition code as an example. Let's create a quantum repetition code `Matching` object on five qubits from a NetworkX graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "p = 0.2\n",
    "g = nx.Graph()\n",
    "g.add_edge(0, 1, qubit_id=0, weight=np.log((1-p)/p), error_probability=p)\n",
    "g.add_edge(1, 2, qubit_id=1, weight=np.log((1-p)/p), error_probability=p)\n",
    "g.add_edge(2, 3, qubit_id=2, weight=np.log((1-p)/p), error_probability=p)\n",
    "g.add_edge(3, 4, qubit_id=3, weight=np.log((1-p)/p), error_probability=p)\n",
    "g.add_edge(4, 5, qubit_id=4, weight=np.log((1-p)/p), error_probability=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the purpose of demonstration, we'll assume that there is also an error process that gives a single hook error on qubits $2$ and $3$, corresponding to a single edge between node $2$ and node $4$. This error will occur with probability `p2`. This can be added using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = 0.12\n",
    "g.add_edge(2, 4, qubit_id={2, 3}, weight=np.log((1-p2)/p2), error_probability=p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since nodes 0 and 5 are incident to only a single edge, they must be specified as being boundary nodes, which can be done by setting their optional `is_boundary` attribute to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.node[0]['is_boundary'] = True\n",
    "g.node[5]['is_boundary'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will connect these boundary nodes with an edge of `weight` zero, and with a `qubit_id` either unspecified or set to `set()` or `-1` (since edges between boundaries do not correspond to qubit faults):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edge(0, 5, weight=0.0, qubit_id=-1, error_probability=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can now use this NetworkX graph to construct the `Matching` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymatching.Matching object with 5 qubits, 4 stabilisers, 2 boundary nodes, and 7 edges>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Matching(g)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the noise and syndrome can be generated separately without PyMatching, if the optional `error_probability` attribute is given to every edge, then the edges can be flipped independently with the `error_probability` assigned to them using the `add_noise` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0]\n",
      "[0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from pymatching import set_seed\n",
    "set_seed(1) # Keep RNG deterministic\n",
    "\n",
    "noise, syndrome = m.add_noise()\n",
    "print(noise)\n",
    "print(syndrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now decode as before using the `decode` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "correction = m.decode(syndrome)\n",
    "print((correction+noise)%2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
