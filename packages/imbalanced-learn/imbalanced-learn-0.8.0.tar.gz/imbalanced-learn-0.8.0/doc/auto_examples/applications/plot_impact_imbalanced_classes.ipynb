{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fitting model on imbalanced datasets and how to fight bias\n\n\nThis example illustrates the problem induced by learning on datasets having\nimbalanced classes. Subsequently, we compare different approaches alleviating\nthese negative effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\n# License: MIT\n\nprint(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Problem definition\n##############################################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n\ndf, y = fetch_openml(\"adult\", version=2, as_frame=True, return_X_y=True)\n# we are dropping the following features:\n# - \"fnlwgt\": this feature was created while studying the \"adult\" dataset.\n#   Thus, we will not use this feature which is not acquired during the survey.\n# - \"education-num\": it is encoding the same information than \"education\".\n#   Thus, we are removing one of these 2 features.\ndf = df.drop(columns=[\"fnlwgt\", \"education-num\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The \"adult\" dataset as a class ratio of about 3:1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "classes_count = y.value_counts()\nclasses_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset is only slightly imbalanced. To better highlight the effect of\nlearning from an imbalanced dataset, we will increase its ratio to 30:1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from imblearn.datasets import make_imbalance\n\nratio = 30\ndf_res, y_res = make_imbalance(\n    df, y, sampling_strategy={classes_count.idxmin(): classes_count.max() // ratio},\n)\ny_res.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the rest of the notebook, we will make a single split to get training\nand testing data. Note that you should use cross-validation to have an\nestimate of the performance variation in practice.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    df_res, y_res, stratify=y_res, random_state=42\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a baseline, we could use a classifier which will always predict the\nmajority class independently of the features provided.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\nscore = dummy_clf.fit(X_train, y_train).score(X_test, y_test)\nprint(f\"Accuracy score of a dummy classifier: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of using the accuracy, we can use the balanced accuracy which will\ntake into account the balancing issue.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n\ny_pred = dummy_clf.predict(X_test)\nscore = balanced_accuracy_score(y_test, y_pred)\nprint(f\"Balanced accuracy score of a dummy classifier: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Strategies to learn from an imbalanced dataset\n##############################################################################\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will first define a helper function which will train a given model\nand compute both accuracy and balanced accuracy. The results will be stored\nin a dataframe\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\n\ndef evaluate_classifier(clf, df_scores, clf_name=None):\n    from sklearn.pipeline import Pipeline\n\n    if clf_name is None:\n        if isinstance(clf, Pipeline):\n            clf_name = clf[-1].__class__.__name__\n        else:\n            clf_name = clf.__class__.__name__\n    acc = clf.fit(X_train, y_train).score(X_test, y_test)\n    y_pred = clf.predict(X_test)\n    bal_acc = balanced_accuracy_score(y_test, y_pred)\n    clf_score = pd.DataFrame(\n        {clf_name: [acc, bal_acc]}, index=[\"Accuracy\", \"Balanced accuracy\"]\n    )\n    df_scores = pd.concat([df_scores, clf_score], axis=1).round(decimals=3)\n    return df_scores\n\n\n# Let's define an empty dataframe to store the results\ndf_scores = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dummy baseline\n..............\n\nBefore to train a real machine learning model, we can store the results\nobtained with our `DummyClassifier`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_scores = evaluate_classifier(dummy_clf, df_scores, \"Dummy\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Linear classifier baseline\n..........................\n\nWe will create a machine learning pipeline using a `LogisticRegression`\nclassifier. In this regard, we will need to one-hot encode the categorical\ncolumns and standardized the numerical columns before to inject the data into\nthe `LogisticRegression` classifier.\n\nFirst, we define our numerical and categorical pipelines.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\n\nnum_pipe = make_pipeline(\n    StandardScaler(), SimpleImputer(strategy=\"mean\", add_indicator=True)\n)\ncat_pipe = make_pipeline(\n    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n    OneHotEncoder(handle_unknown=\"ignore\"),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can create a preprocessor which will dispatch the categorical\ncolumns to the categorical pipeline and the numerical columns to the\nnumerical pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import make_column_selector as selector\n\npreprocessor_linear = ColumnTransformer(\n    [\n        (\"num-pipe\", num_pipe, selector(dtype_include=np.number)),\n        (\"cat-pipe\", cat_pipe, selector(dtype_include=pd.CategoricalDtype)),\n    ],\n    n_jobs=2,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we connect our preprocessor with our `LogisticRegression`. We can\nthen evaluate our model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n\nlr_clf = make_pipeline(preprocessor_linear, LogisticRegression(max_iter=1000))\ndf_scores = evaluate_classifier(lr_clf, df_scores, \"LR\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that our linear model is learning slightly better than our dummy\nbaseline. However, it is impacted by the class imbalance.\n\nWe can verify that something similar is happening with a tree-based model\nsuch as `RandomForestClassifier`. With this type of classifier, we will not\nneed to scale the numerical data, and we will only need to ordinal encode the\ncategorical data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\ncat_pipe = make_pipeline(\n    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"), OrdinalEncoder()\n)\n\npreprocessor_tree = ColumnTransformer(\n    [\n        (\"num-pipe\", num_pipe, selector(dtype_include=np.number)),\n        (\"cat-pipe\", cat_pipe, selector(dtype_include=pd.CategoricalDtype)),\n    ],\n    n_jobs=2,\n)\n\nrf_clf = make_pipeline(\n    preprocessor_tree, RandomForestClassifier(random_state=42, n_jobs=2)\n)\n\ndf_scores = evaluate_classifier(rf_clf, df_scores, \"RF\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `RandomForestClassifier` is as well affected by the class imbalanced,\nslightly less than the linear model. Now, we will present different approach\nto improve the performance of these 2 models.\n\nUse `class_weight`\n..................\n\nMost of the models in `scikit-learn` have a parameter `class_weight`. This\nparameter will affect the computation of the loss in linear model or the\ncriterion in the tree-based model to penalize differently a false\nclassification from the minority and majority class. We can set\n`class_weight=\"balanced\"` such that the weight applied is inversely\nproportional to the class frequency. We test this parametrization in both\nlinear model and tree-based model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lr_clf.set_params(logisticregression__class_weight=\"balanced\")\ndf_scores = evaluate_classifier(lr_clf, df_scores, \"LR with class weight\")\ndf_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rf_clf.set_params(randomforestclassifier__class_weight=\"balanced\")\ndf_scores = evaluate_classifier(rf_clf, df_scores, \"RF with class weight\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that using `class_weight` was really effective for the linear\nmodel, alleviating the issue of learning from imbalanced classes. However,\nthe `RandomForestClassifier` is still biased toward the majority class,\nmainly due to the criterion which is not suited enough to fight the class\nimbalance.\n\nResample the training set during learning\n.........................................\n\nAnother way is to resample the training set by under-sampling or\nover-sampling some of the samples. `imbalanced-learn` provides some samplers\nto do such processing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from imblearn.pipeline import make_pipeline as make_pipeline_with_sampler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nlr_clf = make_pipeline_with_sampler(\n    preprocessor_linear,\n    RandomUnderSampler(random_state=42),\n    LogisticRegression(max_iter=1000),\n)\ndf_scores = evaluate_classifier(lr_clf, df_scores, \"LR with under-sampling\")\ndf_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rf_clf = make_pipeline_with_sampler(\n    preprocessor_tree,\n    RandomUnderSampler(random_state=42),\n    RandomForestClassifier(random_state=42, n_jobs=2),\n)\n\ndf_scores = evaluate_classifier(rf_clf, df_scores, \"RF with under-sampling\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Applying a random under-sampler before the training of the linear model or\nrandom forest, allows to not focus on the majority class at the cost of\nmaking more mistake for samples in the majority class (i.e. decreased\naccuracy).\n\nWe could apply any type of samplers and find which sampler is working best\non the current dataset.\n\nInstead, we will present another way by using classifiers which will apply\nsampling internally.\n\nUse of `BalancedRandomForestClassifier` and `BalancedBaggingClassifier`\n.......................................................................\n\nWe already showed that random under-sampling can be effective on decision\ntree. However, instead of under-sampling once the dataset, one could\nunder-sample the original dataset before to take a bootstrap sample. This is\nthe base of the `BalancedRandomForestClassifier` and\n`BalancedBaggingClassifier`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier\n\nrf_clf = make_pipeline(\n    preprocessor_tree, BalancedRandomForestClassifier(random_state=42, n_jobs=2),\n)\n\ndf_scores = evaluate_classifier(rf_clf, df_scores, \"Balanced RF\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The performance with the `BalancedRandomForestClassifier` is better than\napplying a single random under-sampling. We will use a gradient-boosting\nclassifier within a `BalancedBaggingClassifier`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom imblearn.ensemble import BalancedBaggingClassifier\n\nbag_clf = make_pipeline(\n    preprocessor_tree,\n    BalancedBaggingClassifier(\n        base_estimator=HistGradientBoostingClassifier(random_state=42),\n        n_estimators=10,\n        random_state=42,\n        n_jobs=2,\n    ),\n)\n\ndf_scores = evaluate_classifier(bag_clf, df_scores, \"Balanced bagging\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This last approach is the most effective. The different under-sampling allows\nto bring some diversity for the different GBDT to learn and not focus on a\nportion of the majority class.\n\nWe will repeat the same experiment but with a ratio of 100:1 and make a\nsimilar analysis.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Increase imbalanced ratio\n##############################################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ratio = 100\ndf_res, y_res = make_imbalance(\n    df, y, sampling_strategy={classes_count.idxmin(): classes_count.max() // ratio},\n)\nX_train, X_test, y_train, y_test = train_test_split(\n    df_res, y_res, stratify=y_res, random_state=42\n)\n\ndf_scores = pd.DataFrame()\ndf_scores = evaluate_classifier(dummy_clf, df_scores, \"Dummy\")\nlr_clf = make_pipeline(preprocessor_linear, LogisticRegression(max_iter=1000))\ndf_scores = evaluate_classifier(lr_clf, df_scores, \"LR\")\nrf_clf = make_pipeline(\n    preprocessor_tree, RandomForestClassifier(random_state=42, n_jobs=2)\n)\ndf_scores = evaluate_classifier(rf_clf, df_scores, \"RF\")\nlr_clf.set_params(logisticregression__class_weight=\"balanced\")\ndf_scores = evaluate_classifier(lr_clf, df_scores, \"LR with class weight\")\nrf_clf.set_params(randomforestclassifier__class_weight=\"balanced\")\ndf_scores = evaluate_classifier(rf_clf, df_scores, \"RF with class weight\")\nlr_clf = make_pipeline_with_sampler(\n    preprocessor_linear,\n    RandomUnderSampler(random_state=42),\n    LogisticRegression(max_iter=1000),\n)\ndf_scores = evaluate_classifier(lr_clf, df_scores, \"LR with under-sampling\")\nrf_clf = make_pipeline_with_sampler(\n    preprocessor_tree,\n    RandomUnderSampler(random_state=42),\n    RandomForestClassifier(random_state=42, n_jobs=2),\n)\ndf_scores = evaluate_classifier(rf_clf, df_scores, \"RF with under-sampling\")\nrf_clf = make_pipeline(\n    preprocessor_tree, BalancedRandomForestClassifier(random_state=42, n_jobs=2),\n)\ndf_scores = evaluate_classifier(rf_clf, df_scores)\ndf_scores = evaluate_classifier(bag_clf, df_scores, \"Balanced bagging\")\ndf_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we analyse the results, we can draw similar conclusions than in the\nprevious discussion. However, we can observe that the strategy\n`class_weight=\"balanced\"` does not improve the performance when using a\n`RandomForestClassifier`. A resampling is indeed required. The most effective\nmethod remains the `BalancedBaggingClassifier` using a GBDT as a base\nlearner.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}